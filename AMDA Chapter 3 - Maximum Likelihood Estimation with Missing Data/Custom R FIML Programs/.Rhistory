gradient.crossprod <- c(gradient.mu, gradient.sigma) %*% t(c(gradient.mu, gradient.sigma)) + gradient.crossprod
}
hessian <- gradient.crossprod / nrow(Y)
return(hessian)
}
# optimization settings
stopcriterion <- .00001
maxiterations <- 200
stepsize <- 1
blockreps <- 5
# initialize values
mu.start <- c(0,0,0)
sigma.start <- diag(c(.572,8.716,15.879))
num.vars <- length(mu.start)
num.parms <- length(mu.start) + length(vech(sigma.start))
params <- matrix(c(mu.start, vech(sigma.start)), nrow = 1) %x% matrix(1, nrow = maxiterations, ncol = 1)
logL <- rep(0,maxiterations); logL[1] <- sum(dmvnorm(Y,mu.start,sigma.start, log = T))
# begin optimization
iteration <- 1
maxdiff <- 1
while (maxdiff > stopcriterion) {
# advance iteration index
iteration <- iteration + 1
print(paste0("iteration = ", iteration))
# parameters from iteration t - 1
mu <- params[iteration-1,1:num.vars]
sigma.vech <- params[iteration-1,(num.vars+1):num.parms]
sigma <- matrix(duplication.matrix(length(mu)) %*% sigma.vech, ncol = num.vars)
if(iteration <= blockreps){ # update mu and sigma blocks separately (iteration <= blockreps)
gradient.mu <- gradients(mu,sigma)[1:num.vars]
gradient.sigma <- gradients(mu,sigma)[(num.vars+1):num.parms]
hessian.mu <- hessian(mu,sigma)[1:num.vars,1:num.vars]
hessian.sigma <- hessian(mu,sigma)[(num.vars+1):num.parms,(num.vars+1):num.parms]
mu.new <- params[iteration-1,1:num.vars] - (stepsize * solve(-hessian.mu) %*% gradient.mu)
sigma.vech.new <- params[iteration-1,(num.vars+1):num.parms] - stepsize * solve(diag(diag(hessian.sigma))) %*% gradient.sigma
sigma.new <- matrix(duplication.matrix(length(mu.new)) %*% sigma.vech.new, ncol = num.vars)
logL.new <- sum(dmvnorm(Y,mu.new,sigma.new, log = T))
# adjust step size to ensure that log-likelihood increases
adjust.stepsize <- 0
while (adjust.stepsize == 0) {
mu.new <- params[iteration-1,1:num.vars] - (stepsize * solve(hessian.mu) %*% gradient.mu)
sigma.vech.new <- params[iteration-1,(num.vars+1):num.parms] - stepsize * solve(diag(diag(hessian.sigma))) %*% gradient.sigma
sigma.new <- matrix(duplication.matrix(length(mu.new)) %*% sigma.vech.new, ncol = num.vars)
logL.new <- sum(dmvnorm(Y,mu.new,sigma.new, log = T))
logL.change <- logL.new - logL[iteration-1]
# adaptively change step size to increase log-likelihood
if(logL.change > 0){
params[iteration,1:num.vars] <- mu.new
params[iteration,(num.vars+1):num.parms] <- sigma.vech.new
logL[iteration] <- logL.new
stepsize <- stepsize * 2
adjust.stepsize <- 1
print(paste0("iteration = ", iteration, "; logL(t-1) = ", logL[iteration-1], "; logL(t) = ", logL[iteration], "; logLcha = ", logL.change, "; stepsize = ", stepsize))
} else {
stepsize <- stepsize * .50
print(paste0("iteration = ", iteration, "; logL(t-1) = ", logL[iteration-1], "; logL(t) = ", logL[iteration], "; logLcha = ", logL.change, "; stepsize = ", stepsize))
}
}
} else { # update all parameters simultaneously (iteration > blockreps)
# adjust step size to ensure that log-likelihood increases
adjust.stepsize <- 0
while (adjust.stepsize == 0) {
params.new <- params[iteration-1,] - stepsize * solve(hessian(mu,sigma)) %*% gradients(mu,sigma)
mu.new <- params.new[1:num.vars]
sigma.vech.new <- params.new[(num.vars+1):num.parms]
sigma.new <- matrix(duplication.matrix(length(mu.new)) %*% sigma.vech.new, ncol = num.vars)
logL.new <- sum(dmvnorm(Y,mu.new,sigma.new, log = T))
logL.change <- logL.new - logL[iteration-1]
# adaptively change step size
if(logL.change > 0){
params[iteration,1:num.vars] <- mu.new
params[iteration,(num.vars+1):num.parms] <- sigma.vech.new
logL[iteration] <- logL.new
stepsize <- stepsize * 2
adjust.stepsize <- 1
print(paste0("iteration = ", iteration, "; logL(t-1) = ", logL[iteration-1], "; logL(t) = ", logL[iteration], "; logLcha = ", logL.change, "; stepsize = ", stepsize))
} else {
stepsize <- stepsize * .50
}
} # while loop
} # end else
# calculate max difference between consecutive parameters to assess convergence
if(iteration < maxiterations){
maxdiff <- max(abs(params[iteration,] - params[iteration-1,]))
} else {maxdiff <- stopcriterion}
# compute standard errors after convergence
if(maxdiff < stopcriterion){
hessian.sat <- hessian(mu,sigma)
cov.params <- solve(-hessian.sat)
se.params <- sqrt(diag(cov.params))
}
}
# summarize estimates
summary <- cbind(params[iteration,], se.params)
rownames(summary) <- c("mu.x1","mu.m1","mu.y","var.x1","cov.m1x1", "cov.yx1","var.m1", "cov.ym1", "var.y")
colnames(summary) <- c("Est.", "Std. Err.")
iterhist <- cbind(seq(1:(iteration))-1, logL[1:iteration], params[1:iteration,])
colnames(iterhist) <- c("Iteration", "logL", "mu.x1","mu.m1","mu.y","var.x1","cov.m1x1", "cov.yx1","var.m1", "cov.ym1", "var.y")
print(paste0("Estimation Summary after ", iteration-1, " Newton Iterations:"))
print(summary, 5)
print(paste0("Iteration History:"))
print(iterhist, 10)
#
# check results with lavaan
library(lavaan)
model <- 'x1 ~ 1; m1 ~ 1; y ~ 1;
x1 ~~ m1; x1 ~~ y; m1 ~~ y;
x1 ~~ x1; m1 ~~ m1; y ~~ y;'
fit <- lavaan(model, dat)
lavaan::summary(fit, fit.measures = T)
# my results
print(round(iterhist[nrow(iterhist),2], 3))
print(round(summary, 3))
options(scipen = 999)
library(fdir)
library(matrixcalc)
fdir::set()
# read data
dat <- read.table("./pain.dat")
names(dat) <- c("id", "male", "age", "edugroup", "workhrs",
"exercise", "pain", "anxiety", "stress", "control",
"interfere", "depress", "disability")
# data and missingness indicator
Y <- cbind(dat$control, dat$depress)
R <- Y[,2] == 999
# evaluate first derivatives at current parameter values
deriv.1 <- function(mu, sigma){
# initialize derivative matrices
d.mu <- matrix(0, nrow = 2, ncol = 1)
d.sigma <- rep(0,ncol(duplication.matrix(nrow(sigma))))
# sum individual contributions to derivatives
for(i in 1:N){
# select elements of data and parameter matrices that correspond to observed data
if(R[i]){tau <- s <- matrix(c(1,0), nrow = 1)} else {tau <- s <- diag(2)}
Y.i <- s %*% Y[i,]
mu.i <- s %*% mu
sigma.i <- s %*% sigma %*% t(s)
# compute individual contributions to derivatives
d.mu <- d.mu + t(tau) %*% solve(sigma.i) %*% ((Y.i - mu.i))
d.sigma <- d.sigma + t(duplication.matrix(nrow(sigma))) %*% vec(-.5*(t(tau) %*% solve(sigma.i) %*% tau - t(tau) %*% solve(sigma.i) %*% matrix((Y.i - mu.i), ncol = 1) %*% t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau))
}
return(list(d.mu, d.sigma))
}
# evaluate second derivatives at current parameter values
deriv.2 <- function(mu, sigma){
# initialize derivative matrices
d.mu <- matrix(0, nrow = length(mu), ncol = length(mu))
d.sigma <- matrix(0, nrow = ncol(duplication.matrix(nrow(sigma))), ncol = ncol(duplication.matrix(nrow(sigma))))
d.mu.sigma <- matrix(0, nrow = length(mu), ncol = ncol(duplication.matrix(nrow(sigma))))
# sum individual contributions to derivatives
for(i in 1:N){
# select elements of data and parameter matrices that correspond to observed data
if(R[i]){tau <- s <- matrix(c(1,0), nrow = 1)} else {tau <- s <- diag(2)}
Y.i <- s %*% Y[i,]
mu.i <- s %*% mu
sigma.i <- s %*% sigma %*% t(s)
# compute individual contributions to derivatives
d.mu <- d.mu + t(tau) %*% solve(sigma.i) %*% tau
d.sigma <- d.sigma + t(duplication.matrix(nrow(sigma))) %*% (t(tau) %*% solve(sigma.i) %*% tau %x% (t(tau) %*% solve(sigma.i) %*% matrix((Y.i - mu.i), ncol = 1) %*% t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau  - .5*t(tau) %*% solve(sigma.i) %*% tau)) %*% duplication.matrix(nrow(sigma))
d.mu.sigma <- d.mu.sigma + (t(tau) %*% solve(sigma.i) %*% tau %x% (t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau)) %*% duplication.matrix(nrow(sigma))
}
return(list(-d.mu, -d.sigma, -d.mu.sigma))
}
# constants
nvar <- ncol(Y)
nparms <- nvar + (nvar + 1) * nvar / 2
N <- nrow(Y)
# initialize algorithmic features
stopcriterion <- .0000001
stepsize <- 1
maxiterations <- 100
# starting values
mu.start <- rep(0,nvar)
sigma.start <- diag(2)
# initialize matrices to hold iterative history
params <- matrix(c(mu.start, vech(sigma.start)), nrow = 1) %x% matrix(1, nrow = maxiterations, ncol = 1)
logL <- rep(0,maxiterations)
# begin newton algorithm
iteration <- 1
maxdiff <- 1
while (maxdiff > stopcriterion) {
# advance iteration index
iteration <- iteration + 1
print(paste0("iteration = ", iteration))
# current parameters
mu <- params[iteration-1,1:nvar]
sigma <- matrix(duplication.matrix(nvar) %*% params[iteration-1,(nvar+1):nparms], ncol = nvar)
# log-likelihood evaluated at the current estimates
logL[iteration-1] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# construct derivative matrices
first.derivs <- deriv.1(mu,sigma)
second.derivs  <- deriv.2(mu,sigma)
gradient <- c(first.derivs[[1]], first.derivs[[2]])
zeroblock <- matrix(0, nrow = nrow(second.derivs[[3]]), ncol = ncol(second.derivs[[3]]))
hessian <- rbind(cbind(second.derivs[[1]], zeroblock), cbind(t(zeroblock),second.derivs[[2]]))
# update parameters
params[iteration,] <- params[iteration-1,] - stepsize * solve(hessian) %*% gradient
# calculate max difference between consecutive parameters to assess convergence
if(iteration < maxiterations){
maxdiff <- max(abs(params[iteration,] - params[iteration-1,]))
} else {maxdiff <- stopcriterion}
# compute final log-likelihood and standard errors after convergence
if(maxdiff < stopcriterion){
logL[iteration] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# final parameters
mu <- params[iteration-1,1:nvar]
sigma <- matrix(duplication.matrix(nvar) %*% params[iteration-1,(nvar+1):nparms], ncol = nvar)
# log likelihood evaluated at the final estimates
logL[iteration] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# standard errors with observed information
second.derivs <- deriv.2(mu,sigma)
hessian <- rbind(cbind(second.derivs[[1]], second.derivs[[3]]), cbind(t(second.derivs[[3]]),second.derivs[[2]]))
cov.params <- solve(-hessian)
se.params <- sqrt(diag(cov.params))
}
}
# summarize
summary <- cbind(params[iteration,], se.params)
logL <- cbind(seq(1:(iteration))-1, logL[1:iteration], params[1:iteration,])
rownames(summary) <- c("muX","MuY","varX","covXY", "varX")
colnames(summary) <- c("Est.", "Std. Err.")
colnames(logL) <- c("Iteration", "logL", rownames(summary))
print(paste0("Estimation Summary after ", iteration-1, " Newton Iterations:"))
print(round(summary, digits = 3))
print(paste0("Iteration History:"))
print(round(logL, digits = 15))
options(scipen = 999)
library(fdir)
library(matrixcalc)
# set the location of this file as the working directory
fdir::set()
# read data
dat <- read.table("./pain.dat")
names(dat) <- c("id", "txgrp", "male", "age", "edugroup", "workhrs", "exercise", "paingrps",
"pain", "anxiety", "stress", "control", "depress", "interfere", "disability",
paste0("dep", seq(1:7)), paste0("int", seq(1:6)), paste0("dis", seq(1:6)))
options(scipen = 999)
library(fdir)
library(matrixcalc)
# set the location of this file as the working directory
fdir::set()
# read data
dat <- read.table("pain.dat")
names(dat) <- c("id", "txgrp", "male", "age", "edugroup", "workhrs", "exercise", "paingrps",
"pain", "anxiety", "stress", "control", "depress", "interfere", "disability",
paste0("dep", seq(1:7)), paste0("int", seq(1:6)), paste0("dis", seq(1:6)))
options(scipen = 999)
library(fdir)
library(matrixcalc)
fdir::set()
# read data
dat <- read.table("pain.dat")
names(dat) <- c("id", "male", "age", "edugroup", "workhrs",
"exercise", "pain", "anxiety", "stress", "control",
"interfere", "depress", "disability")
View(dat)
options(scipen = 999)
library(fdir)
library(matrixcalc)
fdir::set()
# read data
dat <- read.table("pain.dat")
names(dat) <- c("id", "male", "age", "edugroup", "workhrs",
"exercise", "pain", "anxiety", "stress", "control",
"interfere", "depress", "disability")
# data and missingness indicator
Y <- cbind(dat$control, dat$depress)
R <- Y[,2] == 999
# evaluate first derivatives at current parameter values
deriv.1 <- function(mu, sigma){
# initialize derivative matrices
d.mu <- matrix(0, nrow = 2, ncol = 1)
d.sigma <- rep(0,ncol(duplication.matrix(nrow(sigma))))
# sum individual contributions to derivatives
for(i in 1:N){
# select elements of data and parameter matrices that correspond to observed data
if(R[i]){tau <- s <- matrix(c(1,0), nrow = 1)} else {tau <- s <- diag(2)}
Y.i <- s %*% Y[i,]
mu.i <- s %*% mu
sigma.i <- s %*% sigma %*% t(s)
# compute individual contributions to derivatives
d.mu <- d.mu + t(tau) %*% solve(sigma.i) %*% ((Y.i - mu.i))
d.sigma <- d.sigma + t(duplication.matrix(nrow(sigma))) %*% vec(-.5*(t(tau) %*% solve(sigma.i) %*% tau - t(tau) %*% solve(sigma.i) %*% matrix((Y.i - mu.i), ncol = 1) %*% t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau))
}
return(list(d.mu, d.sigma))
}
# evaluate second derivatives at current parameter values
deriv.2 <- function(mu, sigma){
# initialize derivative matrices
d.mu <- matrix(0, nrow = length(mu), ncol = length(mu))
d.sigma <- matrix(0, nrow = ncol(duplication.matrix(nrow(sigma))), ncol = ncol(duplication.matrix(nrow(sigma))))
d.mu.sigma <- matrix(0, nrow = length(mu), ncol = ncol(duplication.matrix(nrow(sigma))))
# sum individual contributions to derivatives
for(i in 1:N){
# select elements of data and parameter matrices that correspond to observed data
if(R[i]){tau <- s <- matrix(c(1,0), nrow = 1)} else {tau <- s <- diag(2)}
Y.i <- s %*% Y[i,]
mu.i <- s %*% mu
sigma.i <- s %*% sigma %*% t(s)
# compute individual contributions to derivatives
d.mu <- d.mu + t(tau) %*% solve(sigma.i) %*% tau
d.sigma <- d.sigma + t(duplication.matrix(nrow(sigma))) %*% (t(tau) %*% solve(sigma.i) %*% tau %x% (t(tau) %*% solve(sigma.i) %*% matrix((Y.i - mu.i), ncol = 1) %*% t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau  - .5*t(tau) %*% solve(sigma.i) %*% tau)) %*% duplication.matrix(nrow(sigma))
d.mu.sigma <- d.mu.sigma + (t(tau) %*% solve(sigma.i) %*% tau %x% (t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau)) %*% duplication.matrix(nrow(sigma))
}
return(list(-d.mu, -d.sigma, -d.mu.sigma))
}
# constants
nvar <- ncol(Y)
nparms <- nvar + (nvar + 1) * nvar / 2
N <- nrow(Y)
# initialize algorithmic features
stopcriterion <- .0000001
stepsize <- 1
maxiterations <- 100
# starting values
mu.start <- rep(0,nvar)
sigma.start <- diag(2)
# initialize matrices to hold iterative history
params <- matrix(c(mu.start, vech(sigma.start)), nrow = 1) %x% matrix(1, nrow = maxiterations, ncol = 1)
logL <- rep(0,maxiterations)
# begin newton algorithm
iteration <- 1
maxdiff <- 1
while (maxdiff > stopcriterion) {
# advance iteration index
iteration <- iteration + 1
print(paste0("iteration = ", iteration))
# current parameters
mu <- params[iteration-1,1:nvar]
sigma <- matrix(duplication.matrix(nvar) %*% params[iteration-1,(nvar+1):nparms], ncol = nvar)
# log-likelihood evaluated at the current estimates
logL[iteration-1] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# construct derivative matrices
first.derivs <- deriv.1(mu,sigma)
second.derivs  <- deriv.2(mu,sigma)
gradient <- c(first.derivs[[1]], first.derivs[[2]])
zeroblock <- matrix(0, nrow = nrow(second.derivs[[3]]), ncol = ncol(second.derivs[[3]]))
hessian <- rbind(cbind(second.derivs[[1]], zeroblock), cbind(t(zeroblock),second.derivs[[2]]))
# update parameters
params[iteration,] <- params[iteration-1,] - stepsize * solve(hessian) %*% gradient
# calculate max difference between consecutive parameters to assess convergence
if(iteration < maxiterations){
maxdiff <- max(abs(params[iteration,] - params[iteration-1,]))
} else {maxdiff <- stopcriterion}
# compute final log-likelihood and standard errors after convergence
if(maxdiff < stopcriterion){
logL[iteration] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# final parameters
mu <- params[iteration-1,1:nvar]
sigma <- matrix(duplication.matrix(nvar) %*% params[iteration-1,(nvar+1):nparms], ncol = nvar)
# log likelihood evaluated at the final estimates
logL[iteration] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# standard errors with observed information
second.derivs <- deriv.2(mu,sigma)
hessian <- rbind(cbind(second.derivs[[1]], second.derivs[[3]]), cbind(t(second.derivs[[3]]),second.derivs[[2]]))
cov.params <- solve(-hessian)
se.params <- sqrt(diag(cov.params))
}
}
# summarize
summary <- cbind(params[iteration,], se.params)
logL <- cbind(seq(1:(iteration))-1, logL[1:iteration], params[1:iteration,])
rownames(summary) <- c("muX","MuY","varX","covXY", "varX")
colnames(summary) <- c("Est.", "Std. Err.")
colnames(logL) <- c("Iteration", "logL", rownames(summary))
print(paste0("Estimation Summary after ", iteration-1, " Newton Iterations:"))
print(round(summary, digits = 3))
print(paste0("Iteration History:"))
print(round(logL, digits = 15))
options(scipen = 999)
library(fdir)
library(mvtnorm)
# set working directory to this script's location
fdir::set()
# read data
dat <- read.table("pain.dat")
names(dat) <- c("id", "male", "age", "edugroup", "workhrs",
"exercise", "pain", "anxiety", "stress", "control",
"interfere", "depress", "disability")
# data and missingness indicator
Y <- cbind(dat$control, dat$depress)
R <- Y[,2] == 999
# evaluate first derivatives at current parameter values
deriv.1 <- function(mu, sigma){
# initialize derivative matrices
d.mu <- matrix(0, nrow = 2, ncol = 1)
d.sigma <- rep(0,ncol(duplication.matrix(nrow(sigma))))
# sum individual contributions to derivatives
for(i in 1:N){
# select elements of data and parameter matrices that correspond to observed data
if(R[i]){tau <- s <- matrix(c(1,0), nrow = 1)} else {tau <- s <- diag(2)}
Y.i <- s %*% Y[i,]
mu.i <- s %*% mu
sigma.i <- s %*% sigma %*% t(s)
# compute individual contributions to derivatives
d.mu <- d.mu + t(tau) %*% solve(sigma.i) %*% ((Y.i - mu.i))
d.sigma <- d.sigma + t(duplication.matrix(nrow(sigma))) %*% vec(-.5*(t(tau) %*% solve(sigma.i) %*% tau - t(tau) %*% solve(sigma.i) %*% matrix((Y.i - mu.i), ncol = 1) %*% t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau))
}
return(list(d.mu, d.sigma))
}
# evaluate second derivatives at current parameter values
deriv.2 <- function(mu, sigma){
# initialize derivative matrices
d.mu <- matrix(0, nrow = length(mu), ncol = length(mu))
d.sigma <- matrix(0, nrow = ncol(duplication.matrix(nrow(sigma))), ncol = ncol(duplication.matrix(nrow(sigma))))
d.mu.sigma <- matrix(0, nrow = length(mu), ncol = ncol(duplication.matrix(nrow(sigma))))
# sum individual contributions to derivatives
for(i in 1:N){
# select elements of data and parameter matrices that correspond to observed data
if(R[i]){tau <- s <- matrix(c(1,0), nrow = 1)} else {tau <- s <- diag(2)}
Y.i <- s %*% Y[i,]
mu.i <- s %*% mu
sigma.i <- s %*% sigma %*% t(s)
# compute individual contributions to derivatives
d.mu <- d.mu + t(tau) %*% solve(sigma.i) %*% tau
d.sigma <- d.sigma + t(duplication.matrix(nrow(sigma))) %*% (t(tau) %*% solve(sigma.i) %*% tau %x% (t(tau) %*% solve(sigma.i) %*% matrix((Y.i - mu.i), ncol = 1) %*% t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau  - .5*t(tau) %*% solve(sigma.i) %*% tau)) %*% duplication.matrix(nrow(sigma))
d.mu.sigma <- d.mu.sigma + (t(tau) %*% solve(sigma.i) %*% tau %x% (t(matrix((Y.i - mu.i), ncol = 1)) %*% solve(sigma.i) %*% tau)) %*% duplication.matrix(nrow(sigma))
}
return(list(-d.mu, -d.sigma, -d.mu.sigma))
}
# constants
nvar <- ncol(Y)
nparms <- nvar + (nvar + 1) * nvar / 2
N <- nrow(Y)
# initialize algorithmic features
stopcriterion <- .0000001
stepsize <- 1
maxiterations <- 300
# starting values
# see model-implied moments in Eq. 3.25
g0 <- 5; var.r <- 1; b0 <- 5; b1 <- 0; var.e <- 1
alpha <- c(g0, b0)
beta <- matrix(c(0,b1,0,0), ncol = nvar)
psi <- diag(c(var.r,var.e))
# initialize matrices to hold iterative history
params <- matrix(c(g0,b0,b1,var.r,var.e), nrow = 1) %x% matrix(1, nrow = maxiterations, ncol = 1)
logL <- rep(0,maxiterations)
# begin newton algorithm
iteration <- 1
maxdiff <- 1
while (maxdiff > stopcriterion) {
# advance iteration index
iteration <- iteration + 1
print(paste0("iteration = ", iteration))
# current sem/regression parameters
alpha <- params[iteration-1,1:nvar]
beta <- matrix(c(0,params[iteration-1,nvar+1],0,0), ncol = nvar)
psi <- diag(params[iteration-1,(nparms-1):nparms])
# current model-implied mean vector and covariance matrix
mu <- solve(diag(nvar) - beta) %*% alpha
sigma <- solve(diag(nvar) - beta) %*% psi %*% t(solve(diag(nvar) - beta))
# log-likelihood evaluated at the current estimates
logL[iteration-1] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# construct derivative matrices
first.derivs <- deriv.1(mu,sigma)
second.derivs  <- deriv.2(mu,sigma)
gradient <- c(first.derivs[[1]], first.derivs[[2]])
zeroblock <- matrix(0, nrow = nrow(second.derivs[[3]]), ncol = ncol(second.derivs[[3]]))
hessian <- rbind(cbind(second.derivs[[1]], zeroblock), cbind(t(zeroblock),second.derivs[[2]]))
# derivatives linking model-implied moments to regression parameters (see Table 3.5)
delta <- matrix(0, nrow = nparms, ncol = nparms)
delta[1,1] <- delta[2,2] <- delta[3,4] <- delta[5,5] <- 1
delta[2,1] <- beta[2,1]
delta[2,3] <- alpha[1]
delta[4,3] <- psi[1,1]
delta[4,4] <- beta[2,1]
delta[5,3] <- 2*psi[1,1]*beta[2,1]
delta[5,4] <- beta[2,1]^2
# update parameters
params[iteration,] <- params[iteration-1,] - stepsize * solve(t(delta) %*% hessian %*% (delta)) %*% (t(delta) %*% gradient)
# calculate max difference between consecutive parameters to assess convergence
if(iteration < maxiterations){
maxdiff <- max(abs(params[iteration,] - params[iteration-1,]))
} else {maxdiff <- stopcriterion}
# compute final log-likelihood and standard errors after convergence
if(maxdiff < stopcriterion){
# final sem/regression parameters
alpha <- params[iteration,1:nvar]
beta <- matrix(c(0,params[iteration,nvar+1],0,0), ncol = nvar)
psi <- diag(params[iteration,(nparms-1):nparms])
# final model-implied moments
mu <- solve(diag(nvar) - beta) %*% alpha
sigma <- solve(diag(nvar) - beta) %*% psi %*% t(solve(diag(nvar) - beta))
# log likelihood evaluated at the final model-implied estimates
logL[iteration] <- sum(dmvnorm(Y[R == F,],mu,sigma, log = T)) + sum(dnorm(Y[R == T,1],mu[1],sqrt(sigma[1,1]), log = T))
# final derivatives linking model-implied moments to regression parameters
delta <- matrix(0, nrow = nparms, ncol = nparms)
delta[1,1] <- delta[2,2] <- delta[3,4] <- delta[5,5] <- 1
delta[2,1] <- beta[2,1]
delta[2,3] <- alpha[1]
delta[4,3] <- psi[1,1]
delta[4,4] <- beta[2,1]
delta[5,3] <- 2*psi[1,1]*beta[2,1]
delta[5,4] <- beta[2,1]^2
# standard errors with observed information
second.derivs  <- deriv.2(mu,sigma)
hessian <- rbind(cbind(second.derivs[[1]], second.derivs[[3]]), cbind(t(second.derivs[[3]]), second.derivs[[2]]))
information <- t(delta) %*% hessian %*% (delta)
cov.params <- solve(-information)
se.params <- sqrt(diag(cov.params))
}
}
# summarize
summary <- cbind(params[iteration,c(1,4,2,3,5)], se.params[c(1,4,2,3,5)])
logL <- cbind(seq(1:(iteration))-1, logL[1:iteration], params[1:iteration,c(1,4,2,3,5)])
rownames(summary) <- c("muX","varX","B0","B1","vare")
colnames(summary) <- c("Est.", "Std. Err.")
colnames(logL) <- c("Iteration", "logL", rownames(summary))
print(paste0("Estimation Summary after ", iteration-1, " Newton Iterations:"))
print(round(summary, digits = 3))
print(paste0("Iteration History:"))
print(round(logL, digits = 15))
